"""
	This file shows how to use ngrampy to compute the average surprisal measures from Piantadosi, Tily & Gibson (2011)
	
	NOTE: This has not been extensively tested (the paper used other code). 
	
"""
from ngrampy.LineFile import *
import os
GOOG_DIR = "/home/piantado/Desktop/mit/Corpora/GoogleNGrams/3/"
VOCAB_FILE = "Vocabulary.txt"

# Read the vocabulary file
vocabulary = [ l.strip() for l in open(VOCAB_FILE, "r") ]

G = LineFile(["test3.txt"], header=["w1", "w2", "w3", "cnt123"]) #[GOOG_DIR+"2/2gm-0010"])
#rawG = LineFile([GOOG_DIR+x for x in os.listdir(GOOG_DIR)], header=["w1", "w2", "w3", "cnt123"]) #[GOOG_DIR+"2/2gm-0010"])

G.clean() # already done!
G.restrict_vocabulary("w1 w2 w3", vocabulary) # in fields w1 and w2, restrict our vocabulary
G.sort(keys="w1 w2 w3") # Since we collapsed case, etc. This could also be rawG.sort(keys=["w1","w2","w3"]) in the other format.
G.resum_equal("w1 w2 w3", "cnt123" ) # in collapsing case, etc., we need to re-sum

Gcontext = G.copy()
Gcontext.delete_columns( "w3" ) # delete the columns we don't want
Gcontext.sort("w1 w2" ) # sort this by the one we do want 
Gcontext.resum_equal( "w1 w2", "cnt123" ) # resum equal
Gcontext.rename_column("cnt123", "cnt12") # rename the column since its now a sum of 1
Gcontext.sort("w1 w2") # sort our target by w
G.merge(Gcontext, keys1="w1 w2", tocopy="cnt12") # merge in
Gcontext.delete() # and delete this temporary

# and compute surprisal
G.sort("w3")
G.compute_average_surprisal("w3", "cnt123", "cnt12")

G.cat()
